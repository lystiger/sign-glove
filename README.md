# âœ‹ Sign Glove AI â€“ Real-time Gesture Recognition System

This project enables real-time sign language translation using a smart glove equipped with flex sensors and an IMU. The system collects gesture data, allows dataset management, trains machine learning models, and performs real-time prediction using a trained model.

---

## ğŸ“¦ Tech Stack

- **Backend:** FastAPI + MongoDB + Python
- **AI Model:** TensorFlow Lite (.tflite)
- **Frontend:** React + Vite 
- **Database:** MongoDB (collections: `sensor_data`, `model_results`)

---

## ğŸš€ Features

### ğŸ›ï¸ Sensor + Gesture Management
- `POST /sensor-data` â€“ Store incoming glove sensor values
- `GET/POST/PUT/DELETE /gestures` â€“ Manage labeled gesture sessions

### ğŸ¤– Model Training
- `POST /training` â€“ Manually save training result
- `POST /training/run` â€“ Train a model from CSV or database
- `GET /training` â€“ List all training sessions

### ğŸ§  Prediction
- `POST /predict` â€“ Predict label from 11 sensor values
- `GET /predict/live` â€“ Predict using the most recent MongoDB sensor document

### ğŸ“Š System Dashboard
- `GET /dashboard` â€“ System summary:
  - Total gesture sessions
  - Total training models
  - Average accuracy
  - Last activity timestamp

### ğŸ› ï¸ Admin Tools
- `DELETE /admin/sensor-data` â€“ Clear all sensor data
- `DELETE /admin/training-results` â€“ Clear all training results

---

## ğŸ–¥ï¸ Frontend Pages

| Page              | Path             | Description                              |
|-------------------|------------------|------------------------------------------|
| Dashboard         | `/`              | Welcome panel + live stats               |
| Upload CSV        | `/upload`        | Upload CSV to train                      |
| Manage Gestures   | `/gestures`      | View, edit, delete gesture sessions      |
| Training Results  | `/training`      | View & trigger model training            |
| Predict           | `/predict`       | Manual input of 11 values                |
| Live Predict      | `/predict/live`  | Predict continuously from MongoDB        |
| Admin Tools       | `/admin`         | Clear/reset sensor & model data          |

---

## Frontend Buttons: Functions and Use Cases

### 1. Manual Training Features

- **Manual Training Button**
  - **Function:** Triggers model training on demand using the current cleaned data (`gesture_data.csv`).
  - **Use Case:** Use after collecting new data, cleaning up, or experimenting with different datasets.

- **Upload CSV Button**
  - **Function:** Uploads a CSV file containing gesture data to the backend.
  - **Use Case:** Import data from other devices, collaborators, or re-upload previous data for retraining or analysis. Can be raw or cleaned data.

- **Upload Gesture Training Button**
  - **Function:** Uploads a pre-trained model file (e.g., `.tflite`) for live prediction.
  - **Use Case:** Deploy a model trained offline, revert to a previous model, or test different models for accuracy/performance.

### 2. Automatic Training Features

- **Automated Training (No Button)**
  - **Function:** The backend automatically monitors for new data, runs noise reduction, and triggers training at regular intervals or when new data is detected.
  - **Use Case:** Keeps the model up-to-date as new data is collected, requiring no manual intervention.

- **Live Prediction and TTS**
  - **Function:** The frontend displays live predictions and can convert them to speech automatically or with a button.
  - **Use Case:** See and/or hear the AIâ€™s predictions in real time as gestures are performed.

#### Summary Table

| Button/Feature             | Type         | Function/Use Case                                                                 |
|----------------------------|--------------|-----------------------------------------------------------------------------------|
| **Manual Training**        | Manual       | User triggers model training on demand                                            |
| **Upload CSV**             | Manual       | User uploads gesture data for training or analysis                                |
| **Upload Gesture Training**| Manual       | User uploads a pre-trained model for live prediction                              |
| **Automated Training**     | Automatic    | Backend retrains model automatically when new data is detected                    |
| **Live Prediction & TTS**  | Both         | Shows predictions and speaks them, either automatically or on user request        |

---

## ğŸ—‚ï¸ Project Structure

/backend/
â”œâ”€â”€ routes/
â”‚ â”œâ”€â”€ sensor_routes.py
â”‚ â”œâ”€â”€ gesture_routes.py
â”‚ â”œâ”€â”€ training_routes.py
â”‚ â”œâ”€â”€ predict_routes.py
â”‚ â”œâ”€â”€ admin_routes.py
â”‚ â””â”€â”€ dashboard_routes.py
â”œâ”€â”€ models/
â”‚ â”œâ”€â”€ sensor_data.py
â”‚ â””â”€â”€ model_result.py
â”œâ”€â”€ core/
â”‚ â””â”€â”€ database.py
â”œâ”€â”€ data/
â”‚ â””â”€â”€ gesture_data.csv â† for training
â””â”€â”€ AI/
â””â”€â”€ gesture_model.tflite â† trained model

/frontend/
â”œâ”€â”€ components/
â”‚ â”œâ”€â”€ Dashboard.jsx
â”‚ â”œâ”€â”€ UploadCSV.jsx
â”‚ â”œâ”€â”€ ManageGestures.jsx
â”‚ â”œâ”€â”€ TrainingResults.jsx
â”‚ â”œâ”€â”€ Predict.jsx
â”‚ â”œâ”€â”€ LivePredict.jsx
â”‚ â””â”€â”€ AdminTools.jsx
â”œâ”€â”€ App.jsx
â””â”€â”€ main.jsx