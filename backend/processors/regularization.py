"""
Simple and Effective Regularization Algorithms for Sensor Data Processing
Bao g·ªìm 3 thu·∫≠t to√°n ƒë∆°n gi·∫£n v√† hi·ªáu qu·∫£:
1. Simple Kalman Filter - L·ªçc nhi·ªÖu t·ªëi ∆∞u
2. Weighted Moving Average - Trung b√¨nh tr·ªçng s·ªë th√≠ch ·ª©ng
3. Exponential Smoothing - L√†m m∆∞·ª£t d·ªØ li·ªáu
"""

import logging
import csv
import os
import argparse
from collections import deque
from typing import List, Dict, Optional, Any

class RegularizationAlgorithms:
    """
    Class ch·ª©a 3 thu·∫≠t to√°n regularization ƒë∆°n gi·∫£n v√† hi·ªáu qu·∫£
    """
    
    def __init__(self, window_size: int = 5):
        """
        Kh·ªüi t·∫°o c√°c thu·∫≠t to√°n regularization
        
        Args:
            window_size: K√≠ch th∆∞·ªõc c·ª≠a s·ªï cho c√°c thu·∫≠t to√°n
        """
        self.window_size = window_size
        self.sensor_states = {}  # L∆∞u tr·∫°ng th√°i cho t·ª´ng sensor
        self.buffers = {}  # Buffer cho t·ª´ng sensor
        
    def reset_states(self):
        """Reset t·∫•t c·∫£ tr·∫°ng th√°i v√† buffer"""
        self.sensor_states.clear()
        self.buffers.clear()
        logging.info("All regularization states reset")

    # 1. SIMPLE KALMAN FILTER
    def simple_kalman_filter(self, measurement: float, sensor_id: str) -> float:
        """
        Thu·∫≠t to√°n Kalman Filter ƒë∆°n gi·∫£n - T·ªëi ∆∞u cho real-time
        
        Args:
            measurement: Gi√° tr·ªã ƒëo ƒë∆∞·ª£c hi·ªán t·∫°i
            sensor_id: ID c·ªßa sensor
            
        Returns:
            Gi√° tr·ªã ƒë√£ ƒë∆∞·ª£c l·ªçc
        """
        if sensor_id not in self.sensor_states:
            # Kh·ªüi t·∫°o tr·∫°ng th√°i ban ƒë·∫ßu
            self.sensor_states[sensor_id] = {
                'estimate': measurement,  # ∆Ø·ªõc l∆∞·ª£ng hi·ªán t·∫°i
                'error': 1.0,            # Sai s·ªë ∆∞·ªõc l∆∞·ª£ng
                'process_noise': 0.01,   # Noise c·ªßa qu√° tr√¨nh  
                'measurement_noise': 0.1  # Noise c·ªßa ph√©p ƒëo
            }
            return measurement
        
        state = self.sensor_states[sensor_id]
        
        # Prediction step
        predicted_estimate = state['estimate']
        predicted_error = state['error'] + state['process_noise']
        
        # Update step
        kalman_gain = predicted_error / (predicted_error + state['measurement_noise'])
        
        # C·∫≠p nh·∫≠t ∆∞·ªõc l∆∞·ª£ng
        state['estimate'] = predicted_estimate + kalman_gain * (measurement - predicted_estimate)
        state['error'] = (1 - kalman_gain) * predicted_error
        
        return state['estimate']

    # 2. WEIGHTED MOVING AVERAGE
    def weighted_moving_average(self, measurement: float, sensor_id: str) -> float:
        """
        Trung b√¨nh tr·ªçng s·ªë th√≠ch ·ª©ng - ƒê∆°n gi·∫£n v√† hi·ªáu qu·∫£
        
        Args:
            measurement: Gi√° tr·ªã ƒëo ƒë∆∞·ª£c hi·ªán t·∫°i
            sensor_id: ID c·ªßa sensor
            
        Returns:
            Gi√° tr·ªã ƒë√£ ƒë∆∞·ª£c l·ªçc
        """
        buffer_key = f"wma_{sensor_id}"
        
        if buffer_key not in self.buffers:
            self.buffers[buffer_key] = deque(maxlen=self.window_size)
        
        buffer = self.buffers[buffer_key]
        buffer.append(measurement)
        
        if len(buffer) == 1:
            return measurement
        
        # T·∫°o tr·ªçng s·ªë tƒÉng d·∫ßn (gi√° tr·ªã m·ªõi c√≥ tr·ªçng s·ªë cao h∆°n)
        weights = []
        total_weight = 0
        
        for i in range(len(buffer)):
            weight = i + 1  # Tr·ªçng s·ªë tƒÉng d·∫ßn: 1, 2, 3, 4, 5
            weights.append(weight)
            total_weight += weight
        
        # T√≠nh weighted average
        weighted_sum = sum(buffer[i] * weights[i] for i in range(len(buffer)))
        result = weighted_sum / total_weight
        
        return result

    # 3. EXPONENTIAL SMOOTHING
    def exponential_smoothing(self, measurement: float, sensor_id: str, 
                            alpha: float = 0.3) -> float:
        """
        Exponential Smoothing ƒë∆°n gi·∫£n - Responsive v√† smooth
        
        Args:
            measurement: Gi√° tr·ªã ƒëo ƒë∆∞·ª£c hi·ªán t·∫°i
            sensor_id: ID c·ªßa sensor
            alpha: H·ªá s·ªë smoothing (0 < alpha < 1)
            
        Returns:
            Gi√° tr·ªã ƒë√£ ƒë∆∞·ª£c l√†m m∆∞·ª£t
        """
        if sensor_id not in self.sensor_states:
            self.sensor_states[sensor_id] = {
                'smoothed_value': measurement
            }
            return measurement
        
        state = self.sensor_states[sensor_id]
        
        # Exponential smoothing formula
        state['smoothed_value'] = alpha * measurement + (1 - alpha) * state['smoothed_value']
        
        return state['smoothed_value']

    def apply_single_algorithm(self, data: List[float], algorithm: str = "kalman") -> List[float]:
        """
        √Åp d·ª•ng m·ªôt thu·∫≠t to√°n c·ª• th·ªÉ
        
        Args:
            data: D·ªØ li·ªáu sensor c·∫ßn x·ª≠ l√Ω
            algorithm: Thu·∫≠t to√°n ("kalman", "weighted", "exponential")
            
        Returns:
            D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c regularized
        """
        regularized_data = []
        
        for i, value in enumerate(data):
            sensor_id = f"sensor_{i}"
            
            if algorithm == "kalman":
                result = self.simple_kalman_filter(value, sensor_id)
            elif algorithm == "weighted":
                result = self.weighted_moving_average(value, sensor_id)
            elif algorithm == "exponential":
                result = self.exponential_smoothing(value, sensor_id)
            else:
                logging.warning(f"Unknown algorithm: {algorithm}, using kalman")
                result = self.simple_kalman_filter(value, sensor_id)
            
            regularized_data.append(result)
        
        return regularized_data

    def apply_combined_regularization(self, data: List[float], 
                                    algorithm_weights: Optional[Dict[str, float]] = None) -> List[float]:
        """
        √Åp d·ª•ng k·∫øt h·ª£p 3 thu·∫≠t to√°n v·ªõi tr·ªçng s·ªë
        
        Args:
            data: D·ªØ li·ªáu sensor c·∫ßn x·ª≠ l√Ω
            algorithm_weights: Tr·ªçng s·ªë cho t·ª´ng thu·∫≠t to√°n
                              {'kalman': 0.5, 'weighted': 0.3, 'exponential': 0.2}
                              
        Returns:
            D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c regularized
        """
        if algorithm_weights is None:
            algorithm_weights = {
                'kalman': 0.5,
                'weighted': 0.3,
                'exponential': 0.2
            }
        
        # Normalize weights
        total_weight = sum(algorithm_weights.values())
        for key in algorithm_weights:
            algorithm_weights[key] /= total_weight
        
        regularized_data = []
        
        for i, value in enumerate(data):
            sensor_id = f"sensor_{i}"
            
            # √Åp d·ª•ng t·ª´ng thu·∫≠t to√°n
            kalman_result = self.simple_kalman_filter(value, f"kalman_{sensor_id}")
            weighted_result = self.weighted_moving_average(value, f"weighted_{sensor_id}")
            exp_result = self.exponential_smoothing(value, f"exp_{sensor_id}")
            
            # K·∫øt h·ª£p k·∫øt qu·∫£ theo tr·ªçng s·ªë
            combined_result = (algorithm_weights['kalman'] * kalman_result +
                             algorithm_weights['weighted'] * weighted_result +
                             algorithm_weights['exponential'] * exp_result)
            
            regularized_data.append(combined_result)
        
        return regularized_data

    def apply_adaptive_regularization(self, data: List[float]) -> List[float]:
        """
        √Åp d·ª•ng regularization th√≠ch ·ª©ng - T·ª± ƒë·ªông ch·ªçn thu·∫≠t to√°n ph√π h·ª£p
        Args:
            data: D·ªØ li·ªáu sensor c·∫ßn x·ª≠ l√Ω 
        Returns:
            D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c regularized
        """
        if len(data) < 3:
            return data
        # T√≠nh variance ƒë·ªÉ ƒë√°nh gi√° noise level
        variance = sum((x - sum(data)/len(data))**2 for x in data) / len(data)
        
        # Ch·ªçn thu·∫≠t to√°n d·ª±a tr√™n variance
        if variance > 1.0:
            # Noise cao - d√πng Kalman filter
            weights = {'kalman': 0.7, 'weighted': 0.2, 'exponential': 0.1}
        elif variance > 0.1:
            # Noise trung b√¨nh - d√πng weighted average
            weights = {'kalman': 0.3, 'weighted': 0.5, 'exponential': 0.2}
        else:
            # Noise th·∫•p - d√πng exponential smoothing
            weights = {'kalman': 0.2, 'weighted': 0.3, 'exponential': 0.5}
        
        return self.apply_combined_regularization(data, weights)

    def get_algorithm_stats(self) -> Dict[str, Any]:
        """
        L·∫•y th·ªëng k√™ v·ªÅ hi·ªáu su·∫•t c·ªßa c√°c thu·∫≠t to√°n
        
        Returns:
            Dictionary ch·ª©a th√¥ng tin th·ªëng k√™
        """
        stats = {
            'total_sensors': len(self.sensor_states),
            'active_buffers': len(self.buffers),
            'algorithms': {
                'kalman_states': len([k for k in self.sensor_states.keys() 
                                    if 'estimate' in self.sensor_states[k]]),
                'weighted_buffers': len([k for k in self.buffers.keys() 
                                       if k.startswith('wma_')]),
                'exponential_states': len([k for k in self.sensor_states.keys() 
                                         if 'smoothed_value' in self.sensor_states[k]])
            }
        }
        
        return stats

    def configure_algorithm(self, sensor_id: str, algorithm: str, params: Dict[str, Any]):
        """
        C·∫•u h√¨nh tham s·ªë cho thu·∫≠t to√°n c·ª• th·ªÉ
        
        Args:
            sensor_id: ID c·ªßa sensor
            algorithm: Thu·∫≠t to√°n ("kalman", "weighted", "exponential")
            params: Tham s·ªë c·∫•u h√¨nh
        """
        if algorithm == "kalman" and sensor_id in self.sensor_states:
            state = self.sensor_states[sensor_id]
            if 'process_noise' in params:
                state['process_noise'] = params['process_noise']
            if 'measurement_noise' in params:
                state['measurement_noise'] = params['measurement_noise']
        
        elif algorithm == "weighted":
            if 'window_size' in params:
                buffer_key = f"wma_{sensor_id}"
                if buffer_key in self.buffers:
                    # T·∫°o l·∫°i buffer v·ªõi window_size m·ªõi
                    old_data = list(self.buffers[buffer_key])
                    self.buffers[buffer_key] = deque(
                        old_data[-params['window_size']:], 
                        maxlen=params['window_size']
                    )
        
        logging.info(f"Configured {algorithm} for sensor {sensor_id} with params: {params}")

    def process_csv_file(self, input_path: str, output_path: str, method: str = "adaptive", 
                        window_size: int = 5) -> int:
        """
        X·ª≠ l√Ω file CSV v·ªõi regularization
        
        Args:
            input_path: ƒê∆∞·ªùng d·∫´n file input (raw_data.csv)
            output_path: ƒê∆∞·ªùng d·∫´n file output (clean_data.csv)
            method: Ph∆∞∆°ng ph√°p regularization ("adaptive", "combined", "kalman", "weighted", "exponential")
            window_size: K√≠ch th∆∞·ªõc c·ª≠a s·ªï
            
        Returns:
            S·ªë d√≤ng ƒë√£ x·ª≠ l√Ω
        """
        if not os.path.exists(input_path):
            logging.error(f"Input file not found: {input_path}")
            return 0
        
        # Reset states for new file processing
        self.reset_states()
        
        row_count = 0
        
        try:
            with open(input_path, 'r', newline='', encoding='utf-8') as infile, \
                 open(output_path, 'w', newline='', encoding='utf-8') as outfile:
                
                reader = csv.reader(infile)
                writer = csv.writer(outfile)
                
                # Read and write header
                try:
                    header = next(reader)
                    writer.writerow(header)
                except StopIteration:
                    logging.warning("Input file is empty")
                    return 0
                
                # Process each row
                for row in reader:
                    if len(row) < 3:  # Need at least session_id, label, and one sensor value
                        continue
                    
                    session_id, label, *sensor_values = row
                    
                    # Convert sensor values to float
                    try:
                        sensor_values = list(map(float, sensor_values[:11]))  # First 11 sensor values
                    except ValueError:
                        logging.warning(f"Skipping row {row_count + 1}: invalid sensor values")
                        continue
                    
                    # Apply regularization
                    if method == "adaptive":
                        regularized = self.apply_adaptive_regularization(sensor_values)
                    elif method == "combined":
                        regularized = self.apply_combined_regularization(sensor_values)
                    else:
                        regularized = self.apply_single_algorithm(sensor_values, method)
                    
                    # Write processed row
                    writer.writerow([session_id, label] + [round(val, 3) for val in regularized])
                    row_count += 1
                    
                    if row_count % 1000 == 0:
                        logging.info(f"Processed {row_count} rows...")
            
            logging.info(f"Successfully processed {row_count} rows from {input_path} to {output_path}")
            return row_count
            
        except Exception as e:
            logging.error(f"Error processing CSV file: {e}")
            return 0

# H√†m ti·ªán √≠ch ƒë·ªÉ s·ª≠ d·ª•ng
def create_regularizer(window_size: int = 5) -> RegularizationAlgorithms:
    """
    T·∫°o m·ªôt instance c·ªßa RegularizationAlgorithms
    Args:
        window_size: K√≠ch th∆∞·ªõc c·ª≠a s·ªï   
    Returns:
        Instance c·ªßa RegularizationAlgorithms
    """
    return RegularizationAlgorithms(window_size)

def main():
    """
    CLI interface ƒë·ªÉ ch·ªçn ph∆∞∆°ng ph√°p regularization
    """
    parser = argparse.ArgumentParser(description='Apply regularization algorithms to sensor data')
    parser.add_argument('--input', '-i', default='backend/data/raw_data.csv',
                       help='Input CSV file path (default: backend/data/raw_data.csv)')
    parser.add_argument('--output', '-o', default='backend/data/clean_data.csv',
                       help='Output CSV file path (default: backend/data/clean_data.csv)')
    parser.add_argument('--method', '-m', default='adaptive',
                       choices=['adaptive', 'combined', 'kalman', 'weighted', 'exponential'],
                       help='Regularization method (default: adaptive)')
    parser.add_argument('--window-size', '-w', type=int, default=5,
                       help='Window size for algorithms (default: 5)')
    parser.add_argument('--verbose', '-v', action='store_true',
                       help='Enable verbose logging')
    
    args = parser.parse_args()
    
    # Setup logging
    if args.verbose:
        logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
    else:
        logging.basicConfig(level=logging.WARNING, format='%(asctime)s - %(levelname)s - %(message)s')
    
    # Create regularizer and process file
    regularizer = create_regularizer(args.window_size)
    
    print(f"Processing {args.input} with {args.method} method...")
    row_count = regularizer.process_csv_file(args.input, args.output, args.method, args.window_size)
    
    if row_count > 0:
        print(f"‚úÖ Successfully processed {row_count} rows")
        print(f"üìÅ Output saved to: {args.output}")
    else:
        print("‚ùå No rows were processed")

# Example usage
if __name__ == "__main__":
    # Check if running as CLI
    import sys
    if len(sys.argv) > 1:
        main()
    else:
        # Run example tests
        # T·∫°o regularizer
        regularizer = create_regularizer(window_size=5)
        
        # D·ªØ li·ªáu test v·ªõi noise
        test_data = [1.0, 1.1, 5.0, 1.2, 0.9, 1.1, 1.0, 0.8, 1.2, 1.1]
        
        print("Original data:", test_data)
        
        # Test t·ª´ng thu·∫≠t to√°n
        print("\n=== Single Algorithm Tests ===")
        kalman_result = regularizer.apply_single_algorithm(test_data, "kalman")
        print("Kalman Filter:", [round(x, 3) for x in kalman_result])
        
        regularizer.reset_states()  # Reset ƒë·ªÉ test thu·∫≠t to√°n kh√°c
        weighted_result = regularizer.apply_single_algorithm(test_data, "weighted")
        print("Weighted Moving Average:", [round(x, 3) for x in weighted_result])
        
        regularizer.reset_states()
        exp_result = regularizer.apply_single_algorithm(test_data, "exponential")
        print("Exponential Smoothing:", [round(x, 3) for x in exp_result])
        
        # Test combined regularization
        print("\n=== Combined Regularization ===")
        regularizer.reset_states()
        combined_result = regularizer.apply_combined_regularization(test_data)
        print("Combined Result:", [round(x, 3) for x in combined_result])
        
        # Test adaptive regularization
        print("\n=== Adaptive Regularization ===")
        regularizer.reset_states()
        adaptive_result = regularizer.apply_adaptive_regularization(test_data)
        print("Adaptive Result:", [round(x, 3) for x in adaptive_result])
        
        # Statistics
        print("\n=== Algorithm Stats ===")
        print("Stats:", regularizer.get_algorithm_stats())
        
        print("\n=== CLI Usage Examples ===")
        print("python regularization.py --method adaptive --input raw_data.csv --output clean_data.csv")
        print("python regularization.py -m kalman -i raw_data.csv -o clean_data.csv -w 10")
        print("python regularization.py --method combined --verbose")